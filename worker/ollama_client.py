from __future__ import annotations

import json
import re
import time
from typing import Any, Tuple

import aiohttp

DEFAULT_SYSTEM_PROMPT = (
    "Ð¢Ñ‹ Ð¸Ð·Ð²Ð»ÐµÐºÐ°ÐµÑˆÑŒ Ñ‚ÐµÐ³Ð¸ Ð¸ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ðµ ÑÐ¸Ð³Ð½Ð°Ð»Ñ‹ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°. "
    "Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ð²Ð¸Ð´Ð°: "
    "{\"tags\": [\"...\"], \"emoji\": [\"...\"], "
    "\"code\": {\"sentiment\":0.0, \"urgency\":0.0, \"market\":0.0, "
    "\"macro\":0.0, \"geopolitics\":0.0, \"company\":0.0, "
    "\"commodities\":0.0, \"fx\":0.0, \"rates\":0.0, \"crypto\":0.0, "
    "\"usefulness\":0.0, \"ad\":0.0}}. "
    "Ð¡Ñ‚Ñ€Ð¾Ð³Ð¾ Ð¾Ð´Ð¸Ð½ JSON-Ð¾Ð±ÑŠÐµÐºÑ‚ Ð±ÐµÐ· Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ð¹, Ð±ÐµÐ· Markdown Ð¸ Ð±ÐµÐ· ÐºÐ¾Ð´Ð°. "
    "Ð•ÑÐ»Ð¸ Ð½ÐµÑ‡ÐµÐ³Ð¾ Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ â€” Ð²ÐµÑ€Ð½Ð¸ Ð¿ÑƒÑÑ‚Ñ‹Ðµ Ð¼Ð°ÑÑÐ¸Ð²Ñ‹ Ð¸ Ð½ÑƒÐ»Ð¸. "
    "Ð¢ÐµÐ³Ð¸ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼, Ð±ÐµÐ· ÑÐ¼Ð¾Ð´Ð·Ð¸ Ð¸ Ð±ÐµÐ· #. "
    "ÐšÐ°Ð¶Ð´Ð¾Ðµ ÑÐ»Ð¾Ð²Ð¾ Ñ Ð±Ð¾Ð»ÑŒÑˆÐ¾Ð¹ Ð±ÑƒÐºÐ²Ñ‹. "
    "ÐÐ±Ð±Ñ€ÐµÐ²Ð¸Ð°Ñ‚ÑƒÑ€Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐ¹ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, Ð¦Ð‘, IMOEX2, USD/RUB). "
    "Ð•ÑÐ»Ð¸ Ð²ÑÑ‚Ñ€ÐµÑ‡Ð°ÑŽÑ‚ÑÑ Ð¿Ð¾Ð»Ð½Ñ‹Ðµ Ñ„Ð¾Ñ€Ð¼Ñ‹ (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, Ð¦ÐµÐ½Ñ‚Ñ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð±Ð°Ð½Ðº), "
    "Ð¿Ñ€ÐµÐ´Ð¿Ð¾Ñ‡Ð¸Ñ‚Ð°Ð¹ ÑÐ¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð¸Ðµ (Ð¦Ð‘). "
    "Ð¢ÐµÐ³Ð¸ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð±Ñ‹Ñ‚ÑŒ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ð¼Ð¸ (1-3 ÑÐ»Ð¾Ð²Ð°) Ð¸ Ð² Ð¸Ð¼ÐµÐ½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¼ Ð¿Ð°Ð´ÐµÐ¶Ðµ "
    "(ÐœÐ¾ÑÐ±Ð¸Ñ€Ð¶Ð°, ÐžÐ·Ð¾Ð½, Ð¡Ð¾Ð²ÐºÐ¾Ð¼Ð±Ð°Ð½Ðº â€” Ð½Ðµ ÑÐºÐ»Ð¾Ð½ÑÐ¹). "
    "ÐÐµ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐ¹ Ñ„Ñ€Ð°Ð·Ñ‹ Ð²Ñ€Ð¾Ð´Ðµ 'Ð Ð¾ÑÑ‚ Ð²Ñ‹Ñ€ÑƒÑ‡ÐºÐ¸ ÐÑÑ€Ð¾Ñ„Ð»Ð¾Ñ‚Ð°' â€” "
    "Ð²Ñ‹Ð´ÐµÐ»ÑÐ¹ ÑÑƒÑ‰Ð½Ð¾ÑÑ‚ÑŒ (ÐÑÑ€Ð¾Ñ„Ð»Ð¾Ñ‚) Ð¸ Ñ‚ÐµÐ¼Ñƒ (Ð’Ñ‹Ñ€ÑƒÑ‡ÐºÐ°). "
    "Ð˜Ð·Ð±ÐµÐ³Ð°Ð¹ Ð¾Ð±Ñ‰Ð¸Ñ… Ð¿Ñ€Ð¸Ð»Ð°Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ…/Ð³Ð»Ð°Ð³Ð¾Ð»Ð¾Ð² (ÐšÑ€ÑƒÐ¿Ð½Ñ‹Ðµ, Ð§Ð°ÑÑ‚Ð½Ñ‹Ð¹, Ð—Ð°Ð¼ÐµÐ´Ð»Ð¸Ð»ÑÑ). "
    "ÐÐµ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐ¹ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ñ‡Ð¸ÑÐ»Ð°, Ñ†ÐµÐ½Ñ‹, Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚Ñ‹ Ð¸Ð»Ð¸ Ð´Ð°Ñ‚Ñ‹. "
    "ÐÐµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð»Ð°Ñ‚Ð¸Ð½Ð¸Ñ†Ñƒ, ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ñ€ÑƒÑÑÐºÐ¾Ðµ Ð½Ð°Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ. "
    "Ð­Ð¼Ð¾Ð´Ð·Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¸Ð· ÑÐ¿Ð¸ÑÐºÐ°: "
    "âš ï¸ ðŸ”¥ ðŸ“‰ ðŸ“ˆ ðŸ’° ðŸª™ ðŸ’± ðŸ›¢ï¸ ðŸ¦ ðŸ­ ðŸ§¾ ðŸ“° ðŸ§  ðŸŒ ðŸ›¡ï¸ ðŸ§ª ðŸš€ ðŸŽ¯ âœ… âŒ ðŸ˜¡ ðŸ˜¢ ðŸ˜Š ðŸŽ‰ "
    "ðŸ¥‡ ðŸ¥ˆ ðŸ¥‰ ðŸª¨ ðŸªµ ðŸŒ¾ ðŸŒ½ ðŸ¬ ðŸŒ± â›½ï¸ âš¡ï¸ âœˆï¸ ðŸ›°ï¸ ðŸ  ðŸ„ ðŸŸ ðŸ“Š ðŸ’¹ â˜¢ï¸ "
    "ðŸš¢ ðŸ’¥ ðŸ’£ ðŸŽ® ðŸ•¹ï¸ ðŸ† âš”ï¸ ðŸ‡·ðŸ‡º ðŸ‡ºðŸ‡¸ ðŸ‡¨ðŸ‡³ ðŸ‡ªðŸ‡º ðŸ‡¬ðŸ‡§ ðŸ‡©ðŸ‡ª ðŸ‡«ðŸ‡· ðŸ‡®ðŸ‡¹ ðŸ‡¯ðŸ‡µ ðŸ‡°ðŸ‡· ðŸ‡®ðŸ‡³ ðŸ‡§ðŸ‡· ðŸ‡¹ðŸ‡· ðŸ‡ºðŸ‡¦ ðŸ‡¨ðŸ‡¦ ðŸ‡¦ðŸ‡º "
    "ðŸ‡¸ðŸ‡¦ ðŸ‡¦ðŸ‡ª ðŸ‡®ðŸ‡± ðŸ‡®ðŸ‡· ðŸ‡®ðŸ‡¶ ðŸ‡ªðŸ‡¬ ðŸ‡µðŸ‡± ðŸ‡¨ðŸ‡¿ ðŸ‡³ðŸ‡± ðŸ‡§ðŸ‡ª ðŸ‡ªðŸ‡¸ ðŸ‡µðŸ‡¹ ðŸ‡¸ðŸ‡ª ðŸ‡³ðŸ‡´ ðŸ‡«ðŸ‡® ðŸ‡©ðŸ‡° ðŸ‡¨ðŸ‡­ ðŸ‡¦ðŸ‡¹ "
    "ðŸ‡²ðŸ‡½ ðŸ‡¦ðŸ‡· ðŸ‡¨ðŸ‡± ðŸ‡¨ðŸ‡´ ðŸ‡°ðŸ‡¿ ðŸ‡§ðŸ‡¾ â¬†ï¸ â¬‡ï¸ "
    "(Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾ 4â€“8, Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 10). "
    "Ð¡Ñ‚Ð°Ñ€Ð°Ð¹ÑÑ Ð´ÐµÐ»Ð°Ñ‚ÑŒ ÑÐ¼Ð¾Ð´Ð·Ð¸-Ñ€ÐµÐ±ÑƒÑ Ð² Ð¿Ð¾Ñ€ÑÐ´ÐºÐµ: ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ðµ â†’ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ â†’ Ñ€ÐµÑÑƒÑ€Ñ â†’ ÑÑ‚Ñ€Ð°Ð½Ð°. "
    "ÐŸÑ€Ð¸Ð¼ÐµÑ€: ðŸš¢ðŸ’£ðŸ“‰ðŸ›¢ðŸ‡·ðŸ‡º. "
    "ÐšÐ¾Ð´Ñ‹: sentiment Ð² Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½Ðµ -1..1, Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ðµ 0..1. "
    "usefulness = Ð¿Ð¾Ð»ÐµÐ·Ð½Ð¾ÑÑ‚ÑŒ (0..1), ad = Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ Ñ€ÐµÐºÐ»Ð°Ð¼Ñ‹ (0..1). "
    "ÐÐµ Ð´ÑƒÐ±Ð»Ð¸Ñ€ÑƒÐ¹ Ñ‚ÐµÐ³Ð¸ Ð¸ Ð½Ðµ Ð²Ñ‹Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹."
)


def _repair_json(blob: str) -> str:
    return re.sub(r",\s*([}\]])", r"\1", blob)


def _extract_json(text: str) -> dict[str, Any] | None:
    match = re.search(r"\{.*\}", text, re.DOTALL)
    if not match:
        return None
    blob = match.group(0).strip()
    for candidate in (blob, _repair_json(blob)):
        try:
            return json.loads(candidate)
        except json.JSONDecodeError:
            continue
    return None


def _tokens_per_second(count: int | None, duration_ns: int | None) -> float | None:
    if not count or not duration_ns or duration_ns <= 0:
        return None
    seconds = duration_ns / 1_000_000_000
    if seconds <= 0:
        return None
    return count / seconds


def _clamp(value: float, min_value: float, max_value: float) -> float:
    return max(min_value, min(max_value, value))


def _normalize_code(payload: dict[str, Any] | None) -> dict[str, float]:
    keys = [
        "sentiment",
        "urgency",
        "market",
        "macro",
        "geopolitics",
        "company",
        "commodities",
        "fx",
        "rates",
        "crypto",
        "usefulness",
        "ad",
    ]
    result: dict[str, float] = {}
    for key in keys:
        raw = payload.get(key) if isinstance(payload, dict) else None
        try:
            value = float(raw)
        except (TypeError, ValueError):
            value = 0.0
        if key == "sentiment":
            result[key] = _clamp(value, -1.0, 1.0)
        else:
            result[key] = _clamp(value, 0.0, 1.0)
    return result


MAX_EMOJI = 10


def _merge_code(base: dict[str, float], fallback: dict[str, float]) -> dict[str, float]:
    merged = dict(base)
    for key, value in fallback.items():
        if key == "sentiment":
            if abs(value) > abs(merged.get(key, 0.0)):
                merged[key] = value
            continue
        merged[key] = max(merged.get(key, 0.0), value)
    return merged

FLAG_PATTERNS: dict[str, list[re.Pattern[str]]] = {
    "ðŸ‡·ðŸ‡º": [re.compile(r"\bÑ€Ð¾ÑÑÐ¸\w*\b"), re.compile(r"\bÑ€Ñ„\b")],
    "ðŸ‡ºðŸ‡¸": [re.compile(r"\bÑÑˆÐ°\b"), re.compile(r"\busa\b"), re.compile(r"\bunited states\b"), re.compile(r"\bÐ°Ð¼ÐµÑ€Ð¸Ðº\w*\b")],
    "ðŸ‡¨ðŸ‡³": [re.compile(r"\bÐºÐ¸Ñ‚Ð°Ð¹\w*\b"), re.compile(r"\bÐºÐ½Ñ€\b"), re.compile(r"\bchina\b")],
    "ðŸ‡ªðŸ‡º": [re.compile(r"\bÐµÐ²Ñ€Ð¾ÑÐ¾ÑŽÐ·\b"), re.compile(r"\bÐµÐ²Ñ€Ð¾Ð¿Ð°\b"), re.compile(r"\beu\b"), re.compile(r"\beurozone\b")],
    "ðŸ‡¬ðŸ‡§": [re.compile(r"\bÐ²ÐµÐ»Ð¸ÐºÐ¾Ð±Ñ€Ð¸Ñ‚\w*\b"), re.compile(r"\bÐ±Ñ€Ð¸Ñ‚Ð°Ð½\w*\b"), re.compile(r"\buk\b"), re.compile(r"\bÐ°Ð½Ð³Ð»Ð¸\w*\b")],
    "ðŸ‡©ðŸ‡ª": [re.compile(r"\bÐ³ÐµÑ€Ð¼Ð°Ð½\w*\b"), re.compile(r"\bÐ½ÐµÐ¼ÐµÑ†\w*\b"), re.compile(r"\bdeutsch\w*\b")],
    "ðŸ‡«ðŸ‡·": [re.compile(r"\bÑ„Ñ€Ð°Ð½Ñ†\w*\b"), re.compile(r"\bfrance\b")],
    "ðŸ‡®ðŸ‡¹": [re.compile(r"\bÐ¸Ñ‚Ð°Ð»\w*\b"), re.compile(r"\bitaly\b")],
    "ðŸ‡¯ðŸ‡µ": [re.compile(r"\bÑÐ¿Ð¾Ð½\w*\b"), re.compile(r"\bjapan\b")],
    "ðŸ‡°ðŸ‡·": [re.compile(r"\bÐºÐ¾Ñ€Ðµ\w*\b"), re.compile(r"\bkorea\b")],
    "ðŸ‡®ðŸ‡³": [re.compile(r"\bÐ¸Ð½Ð´Ð¸Ñ\b"), re.compile(r"\bÐ¸Ð½Ð´Ð¸Ð¹ÑÐº\w*\b"), re.compile(r"\bindia\b")],
    "ðŸ‡§ðŸ‡·": [re.compile(r"\bÐ±Ñ€Ð°Ð·Ð¸Ð»\w*\b"), re.compile(r"\bbrazil\b")],
    "ðŸ‡¹ðŸ‡·": [re.compile(r"\bÑ‚ÑƒÑ€Ñ†\w*\b"), re.compile(r"\bturkey\b")],
    "ðŸ‡ºðŸ‡¦": [re.compile(r"\bÑƒÐºÑ€Ð°Ð¸Ð½\w*\b"), re.compile(r"\bukraine\b")],
    "ðŸ‡¨ðŸ‡¦": [re.compile(r"\bÐºÐ°Ð½Ð°Ð´Ð°\b"), re.compile(r"\bcanada\b")],
    "ðŸ‡¦ðŸ‡º": [re.compile(r"\bÐ°Ð²ÑÑ‚Ñ€Ð°Ð»\w*\b"), re.compile(r"\baustralia\b")],
    "ðŸ‡¸ðŸ‡¦": [re.compile(r"\bÑÐ°ÑƒÐ´\w*\b"), re.compile(r"\bksa\b"), re.compile(r"\bsaudi\b")],
    "ðŸ‡¦ðŸ‡ª": [re.compile(r"\bÐ¾Ð°Ñ\b"), re.compile(r"\bÑÐ¼Ð¸Ñ€Ð°Ñ‚\w*\b"), re.compile(r"\buae\b")],
    "ðŸ‡®ðŸ‡±": [re.compile(r"\bÐ¸Ð·Ñ€Ð°Ð¸Ð»\w*\b"), re.compile(r"\bisrael\b")],
    "ðŸ‡®ðŸ‡·": [re.compile(r"\bÐ¸Ñ€Ð°Ð½\b"), re.compile(r"\biran\b")],
    "ðŸ‡®ðŸ‡¶": [re.compile(r"\bÐ¸Ñ€Ð°Ðº\b"), re.compile(r"\biraq\b")],
    "ðŸ‡ªðŸ‡¬": [re.compile(r"\bÐµÐ³Ð¸Ð¿Ñ‚\w*\b"), re.compile(r"\begypt\b")],
    "ðŸ‡µðŸ‡±": [re.compile(r"\bÐ¿Ð¾Ð»ÑŒÑˆ\w*\b"), re.compile(r"\bpoland\b")],
    "ðŸ‡¨ðŸ‡¿": [re.compile(r"\bÑ‡ÐµÑ…\w*\b"), re.compile(r"\bczech\b")],
    "ðŸ‡³ðŸ‡±": [re.compile(r"\bÐ½Ð¸Ð´ÐµÑ€Ð»Ð°Ð½Ð´\w*\b"), re.compile(r"\bÐ³Ð¾Ð»Ð»Ð°Ð½Ð´\w*\b"), re.compile(r"\bnetherlands\b")],
    "ðŸ‡§ðŸ‡ª": [re.compile(r"\bÐ±ÐµÐ»ÑŒÐ³\w*\b"), re.compile(r"\bbelgium\b")],
    "ðŸ‡ªðŸ‡¸": [re.compile(r"\bÐ¸ÑÐ¿Ð°Ð½\w*\b"), re.compile(r"\bspain\b")],
    "ðŸ‡µðŸ‡¹": [re.compile(r"\bÐ¿Ð¾Ñ€Ñ‚ÑƒÐ³Ð°Ð»\w*\b"), re.compile(r"\bportugal\b")],
    "ðŸ‡¸ðŸ‡ª": [re.compile(r"\bÑˆÐ²ÐµÑ†\w*\b"), re.compile(r"\bsweden\b")],
    "ðŸ‡³ðŸ‡´": [re.compile(r"\bÐ½Ð¾Ñ€Ð²ÐµÐ³\w*\b"), re.compile(r"\bnorway\b")],
    "ðŸ‡«ðŸ‡®": [re.compile(r"\bÑ„Ð¸Ð½Ð»ÑÐ½Ð´\w*\b"), re.compile(r"\bfinland\b")],
    "ðŸ‡©ðŸ‡°": [re.compile(r"\bÐ´Ð°Ð½Ð¸\w*\b"), re.compile(r"\bÐ´Ð°Ñ‚ÑÐº\w*\b"), re.compile(r"\bdenmark\b")],
    "ðŸ‡¨ðŸ‡­": [re.compile(r"\bÑˆÐ²ÐµÐ¹Ñ†Ð°Ñ€\w*\b"), re.compile(r"\bswitzerland\b")],
    "ðŸ‡¦ðŸ‡¹": [re.compile(r"\bÐ°Ð²ÑÑ‚Ñ€\w*\b"), re.compile(r"\baustria\b")],
    "ðŸ‡²ðŸ‡½": [re.compile(r"\bÐ¼ÐµÐºÑÐ¸Ðº\w*\b"), re.compile(r"\bmexico\b")],
    "ðŸ‡¦ðŸ‡·": [re.compile(r"\bÐ°Ñ€Ð³ÐµÐ½Ñ‚Ð¸Ð½\w*\b"), re.compile(r"\bargentina\b")],
    "ðŸ‡¨ðŸ‡±": [re.compile(r"\bÑ‡Ð¸Ð»Ð¸\b"), re.compile(r"\bchile\b")],
    "ðŸ‡¨ðŸ‡´": [re.compile(r"\bÐºÐ¾Ð»ÑƒÐ¼Ð±\w*\b"), re.compile(r"\bcolombia\b")],
    "ðŸ‡°ðŸ‡¿": [re.compile(r"\bÐºÐ°Ð·Ð°Ñ…\w*\b"), re.compile(r"\bkazakhstan\b")],
    "ðŸ‡§ðŸ‡¾": [re.compile(r"\bÐ±ÐµÐ»Ð°Ñ€ÑƒÑ\w*\b"), re.compile(r"\bÑ€Ð±\b"), re.compile(r"\bbelarus\b")],
}

ALLOWED_EMOJI = {
    "âš ï¸",
    "ðŸ”¥",
    "ðŸ“‰",
    "ðŸ“ˆ",
    "ðŸ’°",
    "ðŸª™",
    "ðŸ’±",
    "ðŸ›¢ï¸",
    "ðŸ¦",
    "ðŸ­",
    "ðŸ§¾",
    "ðŸ“°",
    "ðŸ§ ",
    "ðŸŒ",
    "ðŸ›¡ï¸",
    "ðŸ§ª",
    "ðŸš€",
    "ðŸŽ¯",
    "âœ…",
    "âŒ",
    "ðŸ˜¡",
    "ðŸ˜¢",
    "ðŸ˜Š",
    "ðŸŽ‰",
    "ðŸ¥‡",
    "ðŸ¥ˆ",
    "ðŸ¥‰",
    "ðŸª¨",
    "ðŸªµ",
    "ðŸŒ¾",
    "ðŸŒ½",
    "ðŸ¬",
    "ðŸŒ±",
    "â›½ï¸",
    "âš¡ï¸",
    "âœˆï¸",
    "ðŸ›°ï¸",
    "ðŸ ",
    "ðŸ„",
    "ðŸŸ",
    "ðŸ“Š",
    "ðŸ’¹",
    "â˜¢ï¸",
    "ðŸš¢",
    "ðŸ’¥",
    "ðŸ’£",
    "ðŸŽ®",
    "ðŸ•¹ï¸",
    "ðŸ†",
    "âš”ï¸",
    "ðŸ‡·ðŸ‡º",
    "ðŸ‡ºðŸ‡¸",
    "ðŸ‡¨ðŸ‡³",
    "ðŸ‡ªðŸ‡º",
    "ðŸ‡¬ðŸ‡§",
    "ðŸ‡©ðŸ‡ª",
    "ðŸ‡«ðŸ‡·",
    "ðŸ‡®ðŸ‡¹",
    "ðŸ‡¯ðŸ‡µ",
    "ðŸ‡°ðŸ‡·",
    "ðŸ‡®ðŸ‡³",
    "ðŸ‡§ðŸ‡·",
    "ðŸ‡¹ðŸ‡·",
    "ðŸ‡ºðŸ‡¦",
    "ðŸ‡¨ðŸ‡¦",
    "ðŸ‡¦ðŸ‡º",
    "ðŸ‡¸ðŸ‡¦",
    "ðŸ‡¦ðŸ‡ª",
    "ðŸ‡®ðŸ‡±",
    "ðŸ‡®ðŸ‡·",
    "ðŸ‡®ðŸ‡¶",
    "ðŸ‡ªðŸ‡¬",
    "ðŸ‡µðŸ‡±",
    "ðŸ‡¨ðŸ‡¿",
    "ðŸ‡³ðŸ‡±",
    "ðŸ‡§ðŸ‡ª",
    "ðŸ‡ªðŸ‡¸",
    "ðŸ‡µðŸ‡¹",
    "ðŸ‡¸ðŸ‡ª",
    "ðŸ‡³ðŸ‡´",
    "ðŸ‡«ðŸ‡®",
    "ðŸ‡©ðŸ‡°",
    "ðŸ‡¨ðŸ‡­",
    "ðŸ‡¦ðŸ‡¹",
    "ðŸ‡²ðŸ‡½",
    "ðŸ‡¦ðŸ‡·",
    "ðŸ‡¨ðŸ‡±",
    "ðŸ‡¨ðŸ‡´",
    "ðŸ‡°ðŸ‡¿",
    "ðŸ‡§ðŸ‡¾",
    "â¬†ï¸",
    "â¬‡ï¸",
}


def _fallback_emoji(tags: list[str], code: dict[str, float], text: str | None) -> list[str]:
    result: list[str] = []
    short_cache: dict[str, re.Pattern[str]] = {}

    def add(emoji: str) -> None:
        if emoji in ALLOWED_EMOJI and emoji not in result:
            result.append(emoji)

    tag_text = " ".join(tags).lower()
    text_l = (text or "").lower()

    def match_key(value: str, key: str) -> bool:
        if len(key) <= 4:
            pattern = short_cache.get(key)
            if pattern is None:
                pattern = re.compile(rf"\b{re.escape(key)}\w*\b")
                short_cache[key] = pattern
            return bool(pattern.search(value))
        return key in value

    def has_any(keys: tuple[str, ...]) -> bool:
        return any(match_key(text_l, k) for k in keys) or any(match_key(tag_text, k) for k in keys)

    def has_any_text(keys: tuple[str, ...]) -> bool:
        return any(match_key(text_l, k) for k in keys)

    # Event / incident (order matters)
    if has_any_text(("Ñ‚Ð°Ð½ÐºÐµÑ€", "ÑÑƒÐ´Ð½Ð¾", "ÐºÐ¾Ñ€Ð°Ð±Ð»", "Ð¿Ð¾Ñ€Ñ‚", "Ð¼Ð¾Ñ€")):
        add("ðŸš¢")
    if has_any_text(("Ð²Ð·Ñ€Ñ‹Ð²", "Ð²Ð·Ð¾Ñ€Ð²Ð°Ð»", "Ð²Ð·Ñ€Ñ‹Ð²Ð¾", "ÑƒÐ´Ð°Ñ€", "Ð¾Ð±ÑÑ‚Ñ€ÐµÐ»", "Ð±Ð¾Ð¼Ð±", "Ð²Ð·Ñ€Ñ‹Ð²Ñ‡Ð°Ñ‚")):
        add("ðŸ’£")
    elif has_any_text(("Ð°Ð²Ð°Ñ€", "ÐºÐ°Ñ‚Ð°ÑÑ‚Ñ€Ð¾Ñ„", "Ð¿Ð¾Ð¶Ð°Ñ€")):
        add("ðŸ’¥")

    # Direction
    if has_any_text(("ÑƒÐ¿Ð°Ð»", "ÑÐ½Ð¸Ð·", "Ð¿Ð°Ð´ÐµÐ½", "Ð¾Ð±Ð²Ð°Ð»", "Ð¿Ñ€Ð¾ÑÐµÐ»")):
        add("ðŸ“‰")
    elif has_any_text(("Ð²Ñ‹Ñ€Ð¾Ñ", "Ð¿Ð¾Ð´Ð½ÑÐ»", "ÑƒÐ²ÐµÐ»Ð¸Ñ‡", "Ð¿Ñ€Ð¸Ð±Ð°Ð²", "Ñ€Ð°ÑÑ‚")):
        add("ðŸ“ˆ")
    elif code.get("market", 0) > 0.6:
        add("ðŸ“ˆ" if code.get("sentiment", 0) >= 0 else "ðŸ“‰")

    # Commodity / domain
    if has_any(("Ð·Ð¾Ð»Ð¾Ñ‚", "gold", "Ð·Ð¾Ð»Ð¾Ñ‚Ð¾")):
        add("ðŸ¥‡")
    if has_any(("ÑÐµÑ€ÐµÐ±Ñ€", "silver")):
        add("ðŸ¥ˆ")
    if has_any(("Ð¼ÐµÐ´ÑŒ", "copper", "bronze", "Ð±Ñ€Ð¾Ð½Ð·")):
        add("ðŸ¥‰")
    if has_any(("Ð¿Ð»Ð°Ñ‚Ð¸Ð½", "Ð¿Ð°Ð»Ð»Ð°Ð´")):
        add("ðŸª™")
    if has_any(("Ð½ÐµÑ„Ñ‚", "brent", "urals")):
        add("ðŸ›¢ï¸")
    if has_any(("Ð³Ð°Ð·", "lng")):
        add("â›½ï¸")
    if has_any(("ÑƒÐ³Ð¾Ð»ÑŒ", "Ñ€ÑƒÐ´Ð°", "Ð¶ÐµÐ»ÐµÐ·", "Ð°Ð»ÑŽÐ¼Ð¸Ð½", "Ð½Ð¸ÐºÐµÐ»", "Ð»Ð¸Ñ‚Ð¸Ð¹", "ÐºÐ¾Ð±Ð°Ð»ÑŒÑ‚", "ÑƒÑ€Ð°Ð½")):
        add("ðŸª¨")
    if has_any(("Ð»ÐµÑ", "Ð´Ñ€ÐµÐ²ÐµÑÐ¸Ð½", "Ð¿Ð¸Ð»Ð¾Ð¼Ð°Ñ‚", "Ð»ÐµÑÐ¾Ð¼Ð°Ñ‚")):
        add("ðŸªµ")
    if has_any(("Ð·ÐµÑ€Ð½", "Ð¿ÑˆÐµÐ½Ð¸Ñ†", "ÑÑ‡Ð¼ÐµÐ½", "Ð¾Ð²ÐµÑ")):
        add("ðŸŒ¾")
    if has_any(("ÐºÑƒÐºÑƒÑ€ÑƒÐ·",)):
        add("ðŸŒ½")
    if has_any(("ÑÐ°Ñ…Ð°Ñ€",)):
        add("ðŸ¬")
    if has_any(("ÑƒÐ´Ð¾Ð±Ñ€", "Ð°Ð³Ñ€Ð¾", "Ð°Ð³Ñ€Ð°Ñ€", "Ð¿Ð¾ÑÐµÐ²")):
        add("ðŸŒ±")
    if has_any(("Ð¼ÑÑÐ¾", "Ð³Ð¾Ð²Ñ", "ÑÐºÐ¾Ñ‚", "Ð¼Ð¾Ð»Ð¾Ðº")):
        add("ðŸ„")
    if has_any(("Ñ€Ñ‹Ð±", "seafood")):
        add("ðŸŸ")
    if has_any(("ÑÐ»ÐµÐºÑ‚Ñ€Ð¾ÑÐ½ÐµÑ€Ð³", "Ð¼Ð¾Ñ‰Ð½Ð¾ÑÑ‚", "ÑÐ½ÐµÑ€Ð³Ð¾ÑÐ¸ÑÑ‚ÐµÐ¼")):
        add("âš¡ï¸")
    if has_any(("Ð°Ð²Ð¸Ð°", "ÑÐ°Ð¼Ð¾Ð»ÐµÑ‚", "Ð°ÑÑ€Ð¾Ð¿Ð¾Ñ€Ñ‚")):
        add("âœˆï¸")
    if has_any(("ÐºÐ¾ÑÐ¼Ð¾Ñ", "ÑÐ¿ÑƒÑ‚Ð½Ð¸Ðº", "space")):
        add("ðŸ›°ï¸")
    if has_any(("Ð½ÐµÐ´Ð²Ð¸Ð¶", "Ð¸Ð¿Ð¾Ñ‚ÐµÐº", "ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ÐµÐ»ÑŒÑÑ‚Ð²")):
        add("ðŸ ")
    if has_any(("ÑÐ´ÐµÑ€", "Ð°Ñ‚Ð¾Ð¼", "Ñ€Ð°Ð´Ð¸Ð°Ñ†")):
        add("â˜¢ï¸")
    if has_any(("Ñ€Ñ‹Ð½Ð¾Ðº", "Ð¸Ð½Ð´ÐµÐºÑ", "ÐºÐ¾Ñ‚Ð¸Ñ€Ð¾Ð²")):
        add("ðŸ“Š")
    if code.get("commodities", 0) > 0.7 and "ðŸ¥‡" not in result and "ðŸ›¢ï¸" not in result and "ðŸª¨" not in result:
        add("ðŸª™")

    # Gaming / esports
    if has_any(("dota", "dota 2", "cs2", "cs:go", "counter-strike", "ÐºÐ¸Ð±ÐµÑ€ÑÐ¿Ð¾Ñ€Ñ‚", "esports", "Ð³ÐµÐ¹Ð¼", "Ð¸Ð³Ñ€", "Ð³ÐµÐ¹Ð¼ÐµÑ€")):
        add("ðŸŽ®")
    if has_any(("Ñ‚ÑƒÑ€Ð½Ð¸Ñ€", "Ñ‡ÐµÐ¼Ð¿Ð¸Ð¾Ð½Ð°Ñ‚", "Ð»Ð¸Ð³Ð°", "season", "Ñ„Ð¸Ð½Ð°Ð»", "playoff", "Ð¿Ð»ÐµÐ¹-Ð¾Ñ„Ñ„")):
        add("ðŸ†")
    if has_any(("Ð¼Ð°Ñ‚Ñ‡", "ÑÐµÑ€Ð¸Ñ", "Ð¿Ñ€Ð¾Ñ‚Ð¸Ð²", "vs")):
        add("âš”ï¸")
    if has_any(("Ð¿Ñ€Ð¸Ð·", "Ð¿Ñ€Ð¸Ð·Ð¾Ð²", "Ð²Ñ‹Ð¸Ð³Ñ€Ð°Ð»", "Ð¿Ð¾Ð±ÐµÐ´", "$", "Ð¼Ð¸Ð»Ð»Ð¸Ð¾Ð½", "Ñ‚Ñ‹Ñ")) and "ðŸ’°" not in result:
        add("ðŸ’°")

    # Geography (strict word-boundary match)
    for flag, patterns in FLAG_PATTERNS.items():
        if any(p.search(text_l) for p in patterns):
            add(flag)

    # Finance / policy / urgency
    if "/" in tag_text or code.get("fx", 0) > 0.6:
        add("ðŸ’±")
    if "Ð±Ð°Ð½Ðº" in tag_text or "Ñ†Ð±" in tag_text or code.get("rates", 0) > 0.7:
        add("ðŸ¦")
    if code.get("geopolitics", 0) > 0.6 and "ðŸŒ" not in result:
        add("ðŸŒ")
    if code.get("urgency", 0) > 0.7:
        add("âš ï¸")

    if not result:
        add("ðŸ“°")

    return result[:MAX_EMOJI]


def _fallback_code(tags: list[str], text: str | None) -> dict[str, float]:
    code = {
        "sentiment": 0.0,
        "urgency": 0.0,
        "market": 0.0,
        "macro": 0.0,
        "geopolitics": 0.0,
        "company": 0.0,
        "commodities": 0.0,
        "fx": 0.0,
        "rates": 0.0,
        "crypto": 0.0,
        "usefulness": 0.0,
        "ad": 0.0,
    }

    tag_text = " ".join(tags).lower()
    text_l = (text or "").lower()

    def has_any(keys: tuple[str, ...]) -> bool:
        return any(k in text_l for k in keys) or any(k in tag_text for k in keys)

    if has_any(("ÑÑ€Ð¾Ñ‡Ð½Ð¾", "Ð¼Ð¾Ð»Ð½Ð¸Ñ", "breaking", "Ð²Ð°Ð¶Ð½Ð¾", "urgent")):
        code["urgency"] = 0.8
    if has_any(("Ñ€Ñ‹Ð½Ð¾Ðº", "Ð¸Ð½Ð´ÐµÐºÑ", "Ð°ÐºÑ†Ð¸", "ÐºÐ¾Ñ‚Ð¸Ñ€Ð¾Ð²", "s&p", "nasdaq", "dow", "imoex", "Ñ€Ñ‚Ñ")):
        code["market"] = 0.7
    if has_any(("Ð¸Ð½Ñ„Ð»ÑÑ†", "Ð²Ð²Ð¿", "gdp", "Ð±ÐµÐ·Ñ€Ð°Ð±Ð¾Ñ‚", "ÑÐºÐ¾Ð½Ð¾Ð¼Ð¸Ðº", "Ð¼Ð°ÐºÑ€Ð¾")):
        code["macro"] = 0.7
    if has_any(("ÑÐ°Ð½ÐºÑ†", "Ð¿ÐµÑ€ÐµÐ³Ð¾Ð²Ð¾Ñ€", "ÐºÐ¾Ð½Ñ„Ð»Ð¸ÐºÑ‚", "Ð¾Ð±Ð¾ÑÑ‚Ñ€ÐµÐ½", "ÑƒÐºÑ€Ð°Ð¸Ð½", "ÑÑˆÐ°", "ÐºÐ¸Ñ‚Ð°Ð¹", "ÐµÑ", "Ð³ÐµÐ¾Ð¿Ð¾Ð»Ð¸Ñ‚")):
        code["geopolitics"] = 0.7
    if has_any(("Ð½ÐµÑ„Ñ‚", "Ð³Ð°Ð·", "brent", "urals", "Ð·Ð¾Ð»Ð¾Ñ‚", "ÑÐµÑ€ÐµÐ±Ñ€", "Ð¼ÐµÑ‚Ð°Ð»Ð»", "ÑƒÐ³Ð¾Ð»ÑŒ", "Ñ€ÑƒÐ´Ð°", "commod")):
        code["commodities"] = 0.7
    if has_any(("Ð²Ð°Ð»ÑŽÑ‚", "usd", "eur", "ÑŽÐ°Ð½ÑŒ", "ÐºÑƒÑ€Ñ", "fx")):
        code["fx"] = 0.7
    if has_any(("Ñ†Ð±", "ÑÑ‚Ð°Ð²Ðº", "ÐºÐ»ÑŽÑ‡ÐµÐ²", "rates")):
        code["rates"] = 0.8
    if has_any(("btc", "eth", "Ð±Ð¸Ñ‚ÐºÐ¾Ð¸Ð½", "ÐºÑ€Ð¸Ð¿Ñ‚", "blockchain", "crypto")):
        code["crypto"] = 0.8
        code["market"] = max(code["market"], 0.6)

    if has_any(("Ð²Ñ‹Ñ€Ð¾Ñ", "Ñ€Ð¾ÑÑ‚", "Ð¿Ñ€Ð¸Ð±Ð°Ð²", "Ð¿Ð¾Ð´Ð¾Ñ€Ð¾Ð¶", "ÑƒÐ²ÐµÐ»Ð¸Ñ‡")):
        code["sentiment"] = 0.4
    if has_any(("ÑƒÐ¿Ð°Ð»", "ÑÐ½Ð¸Ð·", "Ð¾Ð±Ð²Ð°Ð»", "Ð¿Ð¾Ð´ÐµÑˆÐµÐ²", "Ð¿Ñ€Ð¾ÑÐµÐ»")):
        code["sentiment"] = -0.4

    ad_hit = has_any(
        (
            "Ñ€ÐµÐºÐ»Ð°Ð¼",
            "Ð¿Ñ€Ð¾Ð¼Ð¾ÐºÐ¾Ð´",
            "ÑÐºÐ¸Ð´Ðº",
            "ÐºÑƒÐ¿Ð¾Ð½",
            "Ð¿Ð¾Ð´Ð¿Ð¸Ñ",
            "Ð¿Ð°Ñ€Ñ‚Ð½ÐµÑ€",
            "ÑÐ¿Ð¾Ð½ÑÐ¾Ñ€",
            "ÐºÑƒÐ¿Ð¸Ñ‚ÑŒ",
            "Ð·Ð°ÐºÐ°Ð·Ð°Ñ‚ÑŒ",
            "Ð°ÐºÑ†Ð¸Ñ",
            "Ñ€Ð¾Ð·Ñ‹Ð³Ñ€Ñ‹Ñˆ",
            "ÐºÐ¾Ð½ÐºÑƒÑ€Ñ",
            "Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°Ñ†",
            "Ð¿ÐµÑ€ÐµÐ¹Ð´Ð¸",
            "ÑÑÑ‹Ð»ÐºÐ°",
        )
    )
    if ad_hit:
        code["ad"] = 0.85

    usefulness = 0.25
    if code["urgency"] >= 0.7:
        usefulness = max(usefulness, 0.6)
    if has_any(("Ð²Ð¿ÐµÑ€Ð²Ñ‹Ðµ", "Ñ€ÐµÐºÐ¾Ñ€Ð´", "Ð°Ð½Ð¾Ð¼Ð°Ð»", "Ð½ÐµÐ¾Ð±Ñ‹Ñ‡")):
        usefulness = max(usefulness, 0.6)
    if has_any(("Ð¾Ñ‚Ñ‡ÐµÑ‚", "Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚", "Ð´Ð¸Ð²Ð¸Ð´ÐµÐ½", "ipo", "ÑÑ‚Ð°Ð²Ðº", "Ð¸Ð½Ñ„Ð»ÑÑ†")):
        usefulness = max(usefulness, 0.5)
    if has_any(("Ð¿Ð¾Ð´ÐºÐ°ÑÑ‚", "ÑÑ‚Ñ€Ð¸Ð¼", "Ð¸Ð½Ñ‚ÐµÑ€Ð²ÑŒÑŽ")):
        usefulness = min(usefulness, 0.25)
    if code["ad"] >= 0.7:
        usefulness = min(usefulness, 0.15)
    code["usefulness"] = usefulness

    return code


async def generate_tags(
    session: aiohttp.ClientSession,
    base_url: str,
    model: str,
    text: str,
    max_count: int,
    temperature: float = 0.1,
    system_prompt: str | None = None,
    candidates: list[str] | None = None,
) -> Tuple[list[str], list[str], dict[str, float], dict[str, Any]]:
    url = f"{base_url.rstrip('/')}/api/chat"
    started = time.perf_counter()
    prompt = (
        f"Ð’Ñ‹Ð´ÐµÐ»Ð¸ Ð´Ð¾ {max_count} Ñ‚ÐµÐ³Ð¾Ð². Ð’ÐµÑ€Ð½Ð¸ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ JSON.\n\n{text}"
    )
    if candidates:
        uniq = ", ".join(dict.fromkeys(candidates))
        prompt = (
            f"Ð’Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ðµ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ñ‹ (Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ ÐµÑÐ»Ð¸ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾): {uniq}\n\n"
            + prompt
        )

    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt or DEFAULT_SYSTEM_PROMPT},
            {
                "role": "user",
                "content": prompt,
            },
        ],
        "options": {"temperature": temperature},
        "stream": False,
    }
    async with session.post(url, json=payload) as resp:
        resp.raise_for_status()
        data = await resp.json()
        elapsed_ms = round((time.perf_counter() - started) * 1000, 1)
        content = data.get("message", {}).get("content", "")
        parsed = _extract_json(content)
        meta = {
            "model": data.get("model", model),
            "prompt_eval_count": data.get("prompt_eval_count"),
            "prompt_eval_duration": data.get("prompt_eval_duration"),
            "eval_count": data.get("eval_count"),
            "eval_duration": data.get("eval_duration"),
            "total_duration": data.get("total_duration"),
            "elapsed_ms": elapsed_ms,
        }
        meta["prompt_tps"] = _tokens_per_second(
            meta.get("prompt_eval_count"),
            meta.get("prompt_eval_duration"),
        )
        meta["eval_tps"] = _tokens_per_second(
            meta.get("eval_count"),
            meta.get("eval_duration"),
        )
        if not parsed:
            code_norm = _normalize_code({})
            fallback_tags = candidates or []
            fallback_code = _fallback_code(fallback_tags, text)
            code_norm = _merge_code(code_norm, fallback_code)
            return fallback_tags, _fallback_emoji(fallback_tags, code_norm, text), code_norm, meta
        tags = parsed.get("tags")
        emoji = parsed.get("emoji")
        code = parsed.get("code")
        emoji_list: list[str] = []
        if isinstance(emoji, list):
            for item in emoji:
                if not isinstance(item, str):
                    continue
                item = item.strip()
                if item in ALLOWED_EMOJI and item not in emoji_list:
                    emoji_list.append(item)
            if len(emoji_list) > MAX_EMOJI:
                emoji_list = emoji_list[:MAX_EMOJI]

        code_norm = _normalize_code(code if isinstance(code, dict) else {})
        if isinstance(tags, list):
            tags_list = [str(t) for t in tags]
        else:
            tags_list = []

        fallback_code = _fallback_code(tags_list, text)
        code_norm = _merge_code(code_norm, fallback_code)
        fallback = _fallback_emoji(tags_list, code_norm, text)
        safe = {"ðŸ“°", "âš ï¸", "ðŸ˜¡", "ðŸ˜¢", "ðŸ˜Š", "ðŸŽ‰", "ðŸ§ "}
        if emoji_list:
            filtered: list[str] = []
            for item in emoji_list:
                if item in fallback or item in safe:
                    if item not in filtered:
                        filtered.append(item)
            for item in fallback:
                if item not in filtered:
                    filtered.append(item)
            emoji_list = filtered[:MAX_EMOJI]
        else:
            emoji_list = fallback

        return tags_list, emoji_list, code_norm, meta


async def embed_text(
    session: aiohttp.ClientSession,
    base_url: str,
    model: str,
    text: str,
) -> list[float]:
    url = f"{base_url.rstrip('/')}/api/embeddings"
    payload = {
        "model": model,
        "prompt": text,
    }
    async with session.post(url, json=payload) as resp:
        resp.raise_for_status()
        data = await resp.json()
        embedding = data.get("embedding")
        if isinstance(embedding, list):
            return embedding
        return []
